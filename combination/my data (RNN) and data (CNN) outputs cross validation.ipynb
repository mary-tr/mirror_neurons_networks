{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18da0930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6899ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Conv2D,MaxPooling2D,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f56b9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = open(\"data_shuffle_input.csv\")\n",
    "net_data_input = np.genfromtxt(a, delimiter=\",\")\n",
    "b = open(\"data_shuffle_target.csv\")\n",
    "net_data_target = np.genfromtxt(b, delimiter=\",\")\n",
    "c = open(\"mydata_shuffle_input.csv\")\n",
    "net_mydata_input = np.genfromtxt(c, delimiter=\",\")\n",
    "d = open(\"mydata_shuffle_target.csv\")\n",
    "net_mydata_target = np.genfromtxt(d, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8decb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "net_data_input = net_data_input.reshape(net_mydata_input.shape[0],28,28,1)\n",
    "net_mydata_input = net_mydata_input.reshape(net_data_input.shape[0],1,784)\n",
    "net_mydata_input = net_mydata_input / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d2fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eff483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for i in range(len(net_data_target)):\n",
    "    if net_data_target[i][0] == 1:\n",
    "        num.append(0)\n",
    "    if net_data_target[i][1] == 1:\n",
    "        num.append(1)\n",
    "    if net_data_target[i][2] == 1:\n",
    "        num.append(2)\n",
    "    if net_data_target[i][3] == 1:\n",
    "        num.append(3)\n",
    "    if net_data_target[i][4] == 1:\n",
    "        num.append(4)\n",
    "    if net_data_target[i][5] == 1:\n",
    "        num.append(5)\n",
    "    if net_data_target[i][6] == 1:\n",
    "        num.append(6)\n",
    "    if net_data_target[i][7] == 1:\n",
    "        num.append(7)\n",
    "    if net_data_target[i][8] == 1:\n",
    "        num.append(8)\n",
    "    if net_data_target[i][9] == 1:\n",
    "        num.append(9)\n",
    "num = np.asarray(num)        \n",
    "print(type(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9430eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 data\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 395us/sample - loss: 2.2926 - acc: 0.2562\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.2589 - acc: 0.4812\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.2230 - acc: 0.4888\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.1806 - acc: 0.5512\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 2.1285 - acc: 0.5775\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 2.0673 - acc: 0.5938\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9936 - acc: 0.6025\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.9075 - acc: 0.6475\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8120 - acc: 0.6825\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7073 - acc: 0.7325\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.5954 - acc: 0.7725\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.4839 - acc: 0.8050\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.3724 - acc: 0.8200\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.2666 - acc: 0.8275\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.1688 - acc: 0.8363\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.0791 - acc: 0.8475\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.9984 - acc: 0.8575\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.9248 - acc: 0.8687\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.8586 - acc: 0.8725\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.7986 - acc: 0.8800\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.7434 - acc: 0.8850\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.6938 - acc: 0.8938\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.6475 - acc: 0.8988\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.6057 - acc: 0.9013\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5666 - acc: 0.9050\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.5309 - acc: 0.9112\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.4978 - acc: 0.9162\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.4673 - acc: 0.9200\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.4390 - acc: 0.9237\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4127 - acc: 0.9287\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3888 - acc: 0.9325\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3667 - acc: 0.9337\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3461 - acc: 0.9375\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3271 - acc: 0.9400\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.3095 - acc: 0.9438\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.2932 - acc: 0.9450\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.2781 - acc: 0.9513\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.2634 - acc: 0.9563\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2503 - acc: 0.9588\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.2381 - acc: 0.9600\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.2267 - acc: 0.9625\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.2161 - acc: 0.9613\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.2056 - acc: 0.9663\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.1959 - acc: 0.9712\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1875 - acc: 0.9712\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1789 - acc: 0.9750\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1709 - acc: 0.9775\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.1633 - acc: 0.9787\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.1559 - acc: 0.9800\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.1492 - acc: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 310us/sample - loss: 1.8773 - acc: 0.4313\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.4872 - acc: 0.8575\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.2846 - acc: 0.9225\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.1872 - acc: 0.9563\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.1130 - acc: 0.9800\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0736 - acc: 0.9875\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0573 - acc: 0.9950\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0398 - acc: 0.9975\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0317 - acc: 0.9987\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 217us/sample - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 217us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 217us/sample - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 289us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 290us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0028 - acc: 1.0000\n",
      "(20, 1)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 825us/sample - loss: 2.2988 - acc: 0.1238\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 490us/sample - loss: 2.2794 - acc: 0.2850\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 490us/sample - loss: 2.1593 - acc: 0.3225\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 497us/sample - loss: 1.5870 - acc: 0.3200\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 567us/sample - loss: 1.2311 - acc: 0.4150\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 562us/sample - loss: 0.9649 - acc: 0.6475\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 568us/sample - loss: 0.6852 - acc: 0.7638\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 569us/sample - loss: 0.4840 - acc: 0.9250\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 486us/sample - loss: 0.3188 - acc: 0.9762\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.2199 - acc: 0.9787\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 496us/sample - loss: 0.8138 - acc: 0.7113\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 1.2958 - acc: 0.4888\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 541us/sample - loss: 0.5519 - acc: 0.7475\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 613us/sample - loss: 0.4094 - acc: 0.7450\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 1s 629us/sample - loss: 0.3103 - acc: 0.9312\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 1s 628us/sample - loss: 0.2501 - acc: 0.9775\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.1929 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 570us/sample - loss: 0.1479 - acc: 0.9987\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 544us/sample - loss: 0.1146 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 539us/sample - loss: 0.0873 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 549us/sample - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 556us/sample - loss: 0.0923 - acc: 0.9862\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 575us/sample - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 553us/sample - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 546us/sample - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 547us/sample - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 553us/sample - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 566us/sample - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 542us/sample - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 562us/sample - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 557us/sample - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 615us/sample - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 569us/sample - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 1s 659us/sample - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 601us/sample - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 614us/sample - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 571us/sample - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 588us/sample - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 602us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 607us/sample - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 623us/sample - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 608us/sample - loss: 0.0059 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 9 2 6 9 5 4 8 7 1 5 2 6 7 1 5 6 8 1 1 5 9 4 9 4 6 6 9 8 7 0 3 7 3 4 7\n",
      " 6 4 5 4 9 4 4 9 0 3 2 4 8 5 6 7 7 6 1 1 2 4 0 9 2 8 5 9 7 3 8 4 2 3 2 5 8\n",
      " 4 5 4 8 8 5 9 0 4 2 9 8 0 2 5 3 6 1 2 6 5 9 1 6 0 6 4 1 8 4 6 9 7 0 6 4 7\n",
      " 7 1 5 4 9 9 9 0 2 7 5 2 3 6 3 7 2 0 0 6 7 4 4 6 0 0 6 3 7 1 9 2 1 3 0 9 0\n",
      " 7 4 6 5 9 0 9 3 0 1 7 8 8 7 4 4 1 1 3 1 2 9 6 4 5 2 1 7 8 2 5 4 1 1 6 5 8\n",
      " 5 1 1 2 0 7 4 2 6 0 2 3 9 3 3]\n",
      "accuracy is 0.91\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 data\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 303us/sample - loss: 2.2908 - acc: 0.2488\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 2.2563 - acc: 0.4787\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.2191 - acc: 0.4963\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 2.1751 - acc: 0.4925\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.1228 - acc: 0.4875\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.0595 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.9854 - acc: 0.5525\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.8977 - acc: 0.6275\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 1.8013 - acc: 0.6737\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.6951 - acc: 0.7200\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.5837 - acc: 0.7675\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.4713 - acc: 0.7937\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.3608 - acc: 0.8037\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.2546 - acc: 0.8225\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.1550 - acc: 0.8438\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.0642 - acc: 0.8487\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.9813 - acc: 0.8562\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.9066 - acc: 0.8612\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.8403 - acc: 0.8712\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.7788 - acc: 0.8788\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.7245 - acc: 0.8788\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.6755 - acc: 0.8800\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.6309 - acc: 0.8863\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.5894 - acc: 0.8950\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5518 - acc: 0.9075\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.5168 - acc: 0.9075\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.4855 - acc: 0.9112\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4568 - acc: 0.9150\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4303 - acc: 0.9175\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4057 - acc: 0.9275\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3825 - acc: 0.9350\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3609 - acc: 0.9350\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.3418 - acc: 0.9362\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.3233 - acc: 0.9413\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3067 - acc: 0.9513\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.2904 - acc: 0.9550\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2757 - acc: 0.9538\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.2622 - acc: 0.9550\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.2487 - acc: 0.9575\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.2367 - acc: 0.9613\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.2252 - acc: 0.9625\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.2146 - acc: 0.9675\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.2042 - acc: 0.9712\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.1949 - acc: 0.9712\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.1860 - acc: 0.9725\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.1777 - acc: 0.9750\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.1700 - acc: 0.9762\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1624 - acc: 0.9800\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1554 - acc: 0.9825\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.1490 - acc: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 340us/sample - loss: 1.4438 - acc: 0.5325\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.3545 - acc: 0.8988\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.1973 - acc: 0.9538\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.1064 - acc: 0.9775\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0646 - acc: 0.9937\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 296us/sample - loss: 0.0420 - acc: 0.9975\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 281us/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 313us/sample - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 321us/sample - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 291us/sample - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 283us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 291us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 275us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0019 - acc: 1.0000\n",
      "(20, 1)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 793us/sample - loss: 2.2971 - acc: 0.0975\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 1s 631us/sample - loss: 2.2779 - acc: 0.2650\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 2.2449 - acc: 0.2825\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 1s 711us/sample - loss: 1.9975 - acc: 0.3288\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 1s 723us/sample - loss: 1.6354 - acc: 0.3325\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 1s 653us/sample - loss: 1.1922 - acc: 0.6400\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 600us/sample - loss: 0.7198 - acc: 0.7237\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 540us/sample - loss: 0.4050 - acc: 0.9638\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 533us/sample - loss: 0.2151 - acc: 0.9975\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 568us/sample - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 1s 654us/sample - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 616us/sample - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 1s 660us/sample - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 1s 772us/sample - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 1s 669us/sample - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 572us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 1s 676us/sample - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 1s 631us/sample - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 562us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 1s 630us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 1s 653us/sample - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 1s 664us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 1s 647us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 1s 671us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 1s 660us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 643us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 612us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 555us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 542us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 558us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 608us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 569us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 569us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 539us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 573us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 1s 643us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 1s 638us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 1s 632us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 588us/sample - loss: 0.0014 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 1 8 2 9 3 3 3 9 9 1 4 3 6 5 3 7 7 0 0 4 5 5 3 3 1 0 5 3 2 8 0 8 6 4 9\n",
      " 4 6 6 4 5 9 9 0 9 1 7 7 5 4 8 7 3 0 1 9 1 6 4 0 9 3 6 0 6 6 1 6 5 3 1 9 2\n",
      " 2 2 5 3 8 7 7 5 2 2 5 3 2 4 3 7 8 8 7 4 7 9 0 1 3 4 5 0 4 6 7 3 0 7 9 8 1\n",
      " 9 5 3 5 5 3 3 4 8 0 9 2 0 4 7 6 8 9 0 4 6 3 9 6 2 1 3 4 8 3 6 2 1 7 0 9 5\n",
      " 6 2 3 3 5 3 2 3 4 0 9 2 7 9 5 7 9 4 6 9 1 7 0 3 4 7 5 3 4 9 7 4 5 6 1 5 3\n",
      " 4 5 5 7 3 1 2 6 2 6 2 0 9 3 8]\n",
      "accuracy is 0.88\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 data\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 279us/sample - loss: 2.2928 - acc: 0.2750\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.2580 - acc: 0.5775\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.2217 - acc: 0.6313\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.1776 - acc: 0.6562\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.1255 - acc: 0.6562\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.0610 - acc: 0.6600\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 1.9843 - acc: 0.6787\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.8960 - acc: 0.6837\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.7978 - acc: 0.6975\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.6896 - acc: 0.7200\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.5795 - acc: 0.7462\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.4668 - acc: 0.7525\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.3573 - acc: 0.7600\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.2543 - acc: 0.7788\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.1589 - acc: 0.8037\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.0718 - acc: 0.8163\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.9922 - acc: 0.8400\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.9196 - acc: 0.8525\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.8544 - acc: 0.8625\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.7949 - acc: 0.8788\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.7414 - acc: 0.8938\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.6917 - acc: 0.8938\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.6458 - acc: 0.8925\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.6032 - acc: 0.8988\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.5641 - acc: 0.9000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5283 - acc: 0.9062\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4948 - acc: 0.9162\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.4644 - acc: 0.9162\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.4364 - acc: 0.9200\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4100 - acc: 0.9212\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.3857 - acc: 0.9250\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3633 - acc: 0.9337\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3430 - acc: 0.9362\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3231 - acc: 0.9413\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.3058 - acc: 0.9438\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2890 - acc: 0.9463\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.2740 - acc: 0.9500\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.2599 - acc: 0.9513\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.2468 - acc: 0.9575\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2342 - acc: 0.9588\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.2229 - acc: 0.9613\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.2118 - acc: 0.9638\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.2015 - acc: 0.9650\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.1918 - acc: 0.9725\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.1825 - acc: 0.9725\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.1740 - acc: 0.9762\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.1658 - acc: 0.9762\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.1583 - acc: 0.9787\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.1515 - acc: 0.9787\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1445 - acc: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 364us/sample - loss: 1.4444 - acc: 0.5412\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.3617 - acc: 0.8875\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.1933 - acc: 0.9538\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.1079 - acc: 0.9787\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0669 - acc: 0.9937\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0436 - acc: 0.9962\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0309 - acc: 0.9975\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0240 - acc: 0.9987\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 281us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 293us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 215us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.0020 - acc: 1.0000\n",
      "(20, 1)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 665us/sample - loss: 2.2968 - acc: 0.0988\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 477us/sample - loss: 2.2791 - acc: 0.2525\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 481us/sample - loss: 2.2030 - acc: 0.3013\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 493us/sample - loss: 1.6987 - acc: 0.2488\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 507us/sample - loss: 1.2056 - acc: 0.5800\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 509us/sample - loss: 0.9016 - acc: 0.6338\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 514us/sample - loss: 0.6494 - acc: 0.8100\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 505us/sample - loss: 0.5342 - acc: 0.8288\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 503us/sample - loss: 0.4974 - acc: 0.7613\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.4285 - acc: 0.8188\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 500us/sample - loss: 0.3214 - acc: 0.8850\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 515us/sample - loss: 0.2396 - acc: 0.9525\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 536us/sample - loss: 0.1930 - acc: 0.9675\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 523us/sample - loss: 0.1669 - acc: 0.9862\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 500us/sample - loss: 0.5648 - acc: 0.7400\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 503us/sample - loss: 0.6618 - acc: 0.7513\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 506us/sample - loss: 0.4168 - acc: 0.7725\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 506us/sample - loss: 0.2869 - acc: 0.8900\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.1809 - acc: 0.9912\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 506us/sample - loss: 0.1258 - acc: 0.9975\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 511us/sample - loss: 0.1308 - acc: 0.9750\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.9343 - acc: 0.7125\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 501us/sample - loss: 1.7664 - acc: 0.4688\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 501us/sample - loss: 1.1008 - acc: 0.6162\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 500us/sample - loss: 0.6852 - acc: 0.6913\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.4620 - acc: 0.7987\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 521us/sample - loss: 0.3450 - acc: 0.9438\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 565us/sample - loss: 0.2708 - acc: 0.9762\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 598us/sample - loss: 0.1992 - acc: 1.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 516us/sample - loss: 0.1539 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 575us/sample - loss: 0.1295 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 561us/sample - loss: 0.1103 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 530us/sample - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 523us/sample - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 531us/sample - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 505us/sample - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 496us/sample - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 517us/sample - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 502us/sample - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 501us/sample - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 515us/sample - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 515us/sample - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 513us/sample - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 506us/sample - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 539us/sample - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 496us/sample - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 495us/sample - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 501us/sample - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 519us/sample - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 531us/sample - loss: 0.0139 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 1 4 5 7 9 6 2 5 6 2 7 4 3 0 5 0 4 9 7 7 3 7 5 6 4 1 2 5 9 5 0 2 3 7 8\n",
      " 4 2 2 0 0 4 8 8 8 5 9 5 2 9 9 5 4 5 9 0 7 1 0 4 6 7 8 8 2 7 7 7 3 7 6 3 4\n",
      " 1 9 7 0 0 2 2 2 2 0 3 9 1 5 5 0 0 2 6 2 2 0 6 5 4 8 8 3 8 0 3 5 8 4 3 1 6\n",
      " 9 7 7 5 1 4 8 7 8 0 2 7 9 5 1 8 8 1 4 2 6 1 9 9 8 1 7 9 4 5 5 4 4 9 6 2 0\n",
      " 1 8 2 1 1 7 8 6 6 0 9 7 6 8 1 3 5 7 4 0 8 6 0 6 3 7 9 8 7 9 4 6 6 2 6 1 9\n",
      " 2 3 3 7 5 1 9 5 4 2 8 2 6 3 8]\n",
      "accuracy is 0.895\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 data\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 294us/sample - loss: 2.2927 - acc: 0.3175\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.2586 - acc: 0.6350\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.2225 - acc: 0.6875\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 2.1789 - acc: 0.6800\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 2.1263 - acc: 0.6850\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 2.0622 - acc: 0.6762\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.9872 - acc: 0.6675\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.8987 - acc: 0.6600\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.7995 - acc: 0.6750\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.6921 - acc: 0.6938\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.5780 - acc: 0.7188\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.4636 - acc: 0.7425\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.3511 - acc: 0.7625\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.2449 - acc: 0.7850\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.1461 - acc: 0.8075\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.0571 - acc: 0.8188\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.9759 - acc: 0.8363\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.9038 - acc: 0.8525\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.8382 - acc: 0.8625\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.7795 - acc: 0.8675\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.7260 - acc: 0.8838\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.6767 - acc: 0.8888\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.6324 - acc: 0.8925\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.5917 - acc: 0.9075\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.5540 - acc: 0.9100\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5193 - acc: 0.9175\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4873 - acc: 0.9225\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4585 - acc: 0.9250\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.4302 - acc: 0.9262\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.4057 - acc: 0.9300\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3820 - acc: 0.9325\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3607 - acc: 0.9375\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3406 - acc: 0.9400\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3224 - acc: 0.9413\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.3047 - acc: 0.9450\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.2885 - acc: 0.9538\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.2735 - acc: 0.9550\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2596 - acc: 0.9563\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.2467 - acc: 0.9613\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.2346 - acc: 0.9650\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.2232 - acc: 0.9663\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.2128 - acc: 0.9700\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.2022 - acc: 0.9737\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.1934 - acc: 0.9750\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1838 - acc: 0.9775\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.1749 - acc: 0.9775\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1670 - acc: 0.9775\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.1592 - acc: 0.9787\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.1522 - acc: 0.9800\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1453 - acc: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 355us/sample - loss: 1.7862 - acc: 0.4550\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.5166 - acc: 0.8450\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.3130 - acc: 0.9262\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.1989 - acc: 0.9513\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.1348 - acc: 0.9712\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0931 - acc: 0.9912\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0654 - acc: 0.9962\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0514 - acc: 0.9962\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0405 - acc: 0.9975\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0336 - acc: 0.9987\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0288 - acc: 0.9987\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0247 - acc: 0.9987\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0217 - acc: 0.9987\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0191 - acc: 0.9987\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0174 - acc: 0.9987\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0030 - acc: 1.0000\n",
      "(20, 1)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 731us/sample - loss: 2.2993 - acc: 0.1013\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 528us/sample - loss: 2.2810 - acc: 0.2138\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 531us/sample - loss: 2.1946 - acc: 0.3512\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 542us/sample - loss: 1.6278 - acc: 0.3675\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 534us/sample - loss: 1.0796 - acc: 0.5400\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 557us/sample - loss: 0.7489 - acc: 0.7300\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 566us/sample - loss: 0.5345 - acc: 0.8000\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 567us/sample - loss: 0.3833 - acc: 0.9062\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 562us/sample - loss: 0.2615 - acc: 0.9425\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 561us/sample - loss: 0.1898 - acc: 0.9925\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.8071 - acc: 0.7325\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 552us/sample - loss: 0.3242 - acc: 0.8675\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.6463 - acc: 0.7987\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.2968 - acc: 0.8900\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.1904 - acc: 0.9625\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 612us/sample - loss: 0.1759 - acc: 0.9725\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.1552 - acc: 0.9388\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.1756 - acc: 0.9337\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 580us/sample - loss: 0.3901 - acc: 0.8150\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.1840 - acc: 0.9150\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 598us/sample - loss: 0.1985 - acc: 0.9013\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 552us/sample - loss: 0.2712 - acc: 0.8975\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 553us/sample - loss: 0.6104 - acc: 0.7600\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.7068 - acc: 0.7138\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 556us/sample - loss: 0.8791 - acc: 0.7663\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.3018 - acc: 0.9112\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.4927 - acc: 0.8062\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 557us/sample - loss: 0.7520 - acc: 0.7650\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.5297 - acc: 0.7675\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 565us/sample - loss: 0.2973 - acc: 0.8900\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 553us/sample - loss: 0.2410 - acc: 0.9500\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 565us/sample - loss: 0.1982 - acc: 0.9688\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 574us/sample - loss: 0.1655 - acc: 0.9600\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 575us/sample - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 563us/sample - loss: 0.1028 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.0823 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 1s 629us/sample - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 571us/sample - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 1s 636us/sample - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 1s 642us/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 1s 640us/sample - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 1s 638us/sample - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 1s 737us/sample - loss: 0.0144 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 3 7 2 6 0 2 8 5 1 7 8 6 3 1 3 1 3 5 5 0 8 7 5 9 9 2 5 6 5 7 6 3 8 6\n",
      " 7 2 0 0 1 7 2 5 3 7 1 1 1 3 9 9 5 2 6 6 8 4 5 3 7 0 0 1 7 9 1 3 6 4 6 6 3\n",
      " 5 4 2 9 2 9 6 3 2 7 6 0 1 2 5 0 0 7 6 2 8 5 3 8 8 8 4 4 4 6 0 8 8 9 9 3 4\n",
      " 8 7 9 0 4 1 1 4 8 8 3 4 4 3 6 7 7 3 6 3 9 1 1 7 6 7 0 0 3 8 3 0 5 1 1 2 1\n",
      " 8 3 6 7 2 1 7 5 0 7 9 7 1 0 8 2 3 6 3 6 4 2 6 6 1 9 3 6 9 4 7 4 2 4 0 8 5\n",
      " 8 9 8 1 1 1 9 6 4 0 6 8 8 7 8]\n",
      "accuracy is 0.92\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 data\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 2.2928 - acc: 0.2763\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 2.2589 - acc: 0.5663\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.2239 - acc: 0.5987\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.1811 - acc: 0.6212\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 2.1296 - acc: 0.6288\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.0669 - acc: 0.6325\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 1.9928 - acc: 0.6438\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.9066 - acc: 0.6438\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 1.8074 - acc: 0.6550\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 1.7008 - acc: 0.6775\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.5877 - acc: 0.6988\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.4755 - acc: 0.7237\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.3649 - acc: 0.7513\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.2630 - acc: 0.7663\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.1681 - acc: 0.7875\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.0820 - acc: 0.8100\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.0036 - acc: 0.8263\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.9333 - acc: 0.8462\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.8679 - acc: 0.8625\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.8083 - acc: 0.8763\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.7534 - acc: 0.8875\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.7030 - acc: 0.8913\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.6561 - acc: 0.9013\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.6128 - acc: 0.9038\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5735 - acc: 0.9075\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.5363 - acc: 0.9137\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.5019 - acc: 0.9187\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4713 - acc: 0.9237\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4410 - acc: 0.9225\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.4139 - acc: 0.9250\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.3886 - acc: 0.9312\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3651 - acc: 0.9375\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3434 - acc: 0.9425\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3231 - acc: 0.9463\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3046 - acc: 0.9513\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.2878 - acc: 0.9538\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.2721 - acc: 0.9550\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.2572 - acc: 0.9600\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.2440 - acc: 0.9625\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.2305 - acc: 0.9675\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.2184 - acc: 0.9712\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.2075 - acc: 0.9725\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1972 - acc: 0.9712\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.1869 - acc: 0.9750\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1779 - acc: 0.9750\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.1692 - acc: 0.9787\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.1614 - acc: 0.9787\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.1539 - acc: 0.9800\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1466 - acc: 0.9800\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.1398 - acc: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 376us/sample - loss: 2.2459 - acc: 0.4000\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.6975 - acc: 0.8000\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.3905 - acc: 0.8875\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.2468 - acc: 0.9488\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.1651 - acc: 0.9650\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.1156 - acc: 0.9825\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0801 - acc: 0.9925\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0596 - acc: 0.9925\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0448 - acc: 0.9975\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0358 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0310 - acc: 0.9987\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 275us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 304us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.0034 - acc: 1.0000\n",
      "(20, 1)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 935us/sample - loss: 2.2963 - acc: 0.1037\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 1s 728us/sample - loss: 2.2759 - acc: 0.1925\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 1s 679us/sample - loss: 2.2148 - acc: 0.1462\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 1.7411 - acc: 0.2587\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 1s 718us/sample - loss: 1.3426 - acc: 0.3975\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.9910 - acc: 0.5875\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.6909 - acc: 0.8413\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 1s 710us/sample - loss: 0.4599 - acc: 0.9000\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 1s 704us/sample - loss: 0.4442 - acc: 0.8375\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 1s 699us/sample - loss: 0.4084 - acc: 0.8238\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.2871 - acc: 0.9062\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 1s 703us/sample - loss: 0.2514 - acc: 0.8925\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 1s 703us/sample - loss: 0.1758 - acc: 0.9825\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 1s 704us/sample - loss: 0.1334 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.0964 - acc: 0.9962\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 1s 722us/sample - loss: 0.2681 - acc: 0.8662\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 1s 735us/sample - loss: 0.3434 - acc: 0.8400\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 1s 750us/sample - loss: 0.5683 - acc: 0.7912\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 1s 754us/sample - loss: 1.1551 - acc: 0.5800\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 1s 748us/sample - loss: 0.5167 - acc: 0.7962\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.3446 - acc: 0.8512\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 1s 742us/sample - loss: 0.2138 - acc: 0.9962\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 1s 744us/sample - loss: 0.1605 - acc: 0.9825\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 1s 730us/sample - loss: 0.1167 - acc: 0.9975\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 1s 738us/sample - loss: 0.0910 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 1s 713us/sample - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 1s 725us/sample - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 1s 724us/sample - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 1s 723us/sample - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 721us/sample - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 1s 717us/sample - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 1s 727us/sample - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 1s 722us/sample - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 1s 722us/sample - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 1s 733us/sample - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 1s 712us/sample - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 1s 701us/sample - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 1s 729us/sample - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 1s 722us/sample - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 1s 701us/sample - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 1s 703us/sample - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 1s 703us/sample - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 1s 719us/sample - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 1s 778us/sample - loss: 0.0078 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 1 8 0 6 9 9 2 0 3 6 7 1 3 3 5 8 0 5 7 2 3 9 0 5 7 2 5 2 3 8 5 8 0 8\n",
      " 9 8 7 9 8 7 5 0 5 1 7 3 1 6 3 6 5 6 9 2 5 1 3 6 2 9 1 4 8 7 8 0 5 2 7 4 0\n",
      " 2 9 0 2 2 7 5 8 8 2 2 9 6 9 4 2 0 0 5 7 3 9 1 8 5 1 1 9 0 4 2 0 1 4 0 1 2\n",
      " 2 8 0 0 1 6 5 4 4 4 8 1 5 8 8 1 4 8 8 3 9 0 7 4 8 4 2 2 5 8 1 3 9 1 0 3 0\n",
      " 8 3 4 9 2 4 0 6 8 0 2 9 9 5 7 1 7 2 3 5 7 5 1 8 5 0 1 2 1 5 1 4 8 4 0 2 9\n",
      " 0 0 1 6 0 6 8 5 8 3 4 8 6 3 5]\n",
      "accuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5)\n",
    "acc_per_fold = []\n",
    "acc = []\n",
    "loss = []\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(net_data_input, net_data_target, net_mydata_input):\n",
    "\n",
    "    # Define the model architecture for net mydata\n",
    "    rnn_model_data = Sequential()\n",
    "    #rnn_model.add(Flatten())\n",
    "    rnn_model_data.add(LSTM(256,input_shape=net_mydata_input[0].shape,activation=\"tanh\"))\n",
    "    #rnn_model.add(SimpleRNN(128,input_shape=xtrain[0].shape,return_sequences=True))\n",
    "    #rnn_model.add(SimpleRNN(128))\n",
    "    rnn_model_data.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "  # Compile the model\n",
    "    rnn_model_data.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} data')\n",
    "\n",
    "  # Fit data to model\n",
    "    history_mydata = rnn_model_data.fit(net_mydata_input[train], net_data_target[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "\n",
    "    \n",
    "    predictions_mydata_train = rnn_model_data.predict(net_mydata_input[train])\n",
    "    classes_mydata_train = np.argmax(predictions_mydata_train, axis = 1)\n",
    "    classes_mydata_train = tf.keras.utils.to_categorical(classes_mydata_train,10)\n",
    "    \n",
    "    predictions_mydata_test = rnn_model_data.predict(net_mydata_input[test])\n",
    "    classes_mydata_test = np.argmax(predictions_mydata_test, axis = 1)\n",
    "    classes_mydata_test = tf.keras.utils.to_categorical(classes_mydata_test,10)\n",
    "    \n",
    "    \n",
    "    # Define the model architecture for net data\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='tanh', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Generate a print\n",
    "    # Fit data to model\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} mydata')\n",
    "    history_data = model.fit(net_data_input[train], net_data_target[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    predictions_data_train = model.predict(net_data_input[train])\n",
    "    classes_data_train = np.argmax(predictions_data_train, axis = 1)\n",
    "    classes_data_train = tf.keras.utils.to_categorical(classes_data_train,10)\n",
    "\n",
    "    predictions_data_test = model.predict(net_data_input[test])\n",
    "    classes_data_test = np.argmax(predictions_data_test, axis = 1)\n",
    "    classes_data_test = tf.keras.utils.to_categorical(classes_data_test,10)\n",
    "    \n",
    "    #make train list input\n",
    "    joined_list_train = []\n",
    "    joined_list_test = []\n",
    "\n",
    "    for i in range(800):\n",
    "        b = [*classes_data_train[i], *classes_mydata_train[i]]\n",
    "        joined_list_train.append(b)\n",
    "        \n",
    "    for j in range(200):\n",
    "        a = [*classes_data_test[j], *classes_mydata_test[j]]\n",
    "        joined_list_test.append(a)\n",
    "    \n",
    "    \n",
    "    joined_list_train = np.asarray(joined_list_train)\n",
    "    joined_list_test = np.asarray(joined_list_test)\n",
    "    \n",
    "    joined_list_train = joined_list_train.reshape(joined_list_train.shape[0],20,1)\n",
    "\n",
    "    joined_list_test = joined_list_test.reshape(joined_list_test.shape[0],20,1)\n",
    "    \n",
    "  # Define the model architecture for net data\n",
    "    print(joined_list_train[0].shape)\n",
    "    rnn_model_outputs = Sequential()\n",
    "    #rnn_model.add(Flatten())\n",
    "    rnn_model_outputs.add(LSTM(256,input_shape=joined_list_train[0].shape,activation=\"tanh\"))\n",
    "    #rnn_model.add(SimpleRNN(128,input_shape=xtrain[0].shape,return_sequences=True))\n",
    "    #rnn_model.add(SimpleRNN(128))\n",
    "    rnn_model_outputs.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "  # Compile the model\n",
    "    rnn_model_outputs.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} outputs')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = rnn_model_outputs.fit(joined_list_train, net_data_target[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "    scores = rnn_model_outputs.evaluate(joined_list_test, net_data_target[test], verbose=0)\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    predictions = rnn_model_outputs.predict(joined_list_test)\n",
    "    classes = np.argmax(predictions, axis = 1)\n",
    "    print(num[test])\n",
    "    acc_per_fold.append(accuracy_score(num[test],classes))\n",
    "    \n",
    "    print('accuracy is ' + str(accuracy_score(num[test],classes)))\n",
    "    \n",
    "  # Generate generalization metrics\n",
    "    acc.append(history.history['acc'])\n",
    "    loss.append(history.history['loss'])\n",
    "    \n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d15f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.0699543434567749 - Accuracy: 0.91%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.4709418201446534 - Accuracy: 0.88%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.9999448609352112 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.8306843361258507 - Accuracy: 0.92%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 1.2324671506881715 - Accuracy: 0.9%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.901 (+- 0.013564659966250548)\n",
      "> Loss: 1.1207985022701323\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6696951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CNN(MN)_outputs_cross_validation_acc.csv',acc, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f38027",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CNN(MN)_outputs_cross_validation_loss.csv',loss, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
