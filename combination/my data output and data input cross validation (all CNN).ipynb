{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449d1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06be875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Conv2D,MaxPooling2D,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3c90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = open(\"data_shuffle_input.csv\")\n",
    "net_data_input = np.genfromtxt(a, delimiter=\",\")\n",
    "b = open(\"data_shuffle_target.csv\")\n",
    "net_data_target = np.genfromtxt(b, delimiter=\",\")\n",
    "c = open(\"mydata_shuffle_input.csv\")\n",
    "net_mydata_input = np.genfromtxt(c, delimiter=\",\")\n",
    "d = open(\"mydata_shuffle_target.csv\")\n",
    "net_mydata_target = np.genfromtxt(d, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345118fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.14901961\n",
      " 0.92941176 0.41960784 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25098039 0.99215686 0.72941176\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.25098039 0.99215686 0.83137255 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25098039\n",
      " 0.99215686 0.83137255 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25098039 0.99215686 0.83137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.66666667 0.99607843 0.83529412 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49411765\n",
      " 0.99215686 0.83137255 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.45882353 0.99215686 0.45098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.25098039 0.99215686 0.51764706 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25098039\n",
      " 0.99215686 0.83137255 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25490196 1.         0.83529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.25098039 0.99215686 0.69019608 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.4627451\n",
      " 0.99215686 0.41960784 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.6627451  0.99215686 0.41960784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6627451  0.99215686 0.41960784 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.66666667\n",
      " 1.         0.41960784 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.6627451  0.99215686 0.41960784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6627451  0.99215686 0.46666667 0.05882353 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.6627451\n",
      " 0.99215686 0.99607843 0.65882353 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.21568627 0.9254902  0.50980392\n",
      " 0.10980392 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "net_data_input = net_data_input / 255\n",
    "net_data_input = net_data_input.reshape(net_data_input.shape[0],1,784)\n",
    "net_mydata_input = net_mydata_input.reshape(net_mydata_input.shape[0],28,28,1)\n",
    "\n",
    "print(net_data_input[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3681d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4738915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for i in range(len(net_data_target)):\n",
    "    if net_data_target[i][0] == 1:\n",
    "        num.append(0)\n",
    "    if net_data_target[i][1] == 1:\n",
    "        num.append(1)\n",
    "    if net_data_target[i][2] == 1:\n",
    "        num.append(2)\n",
    "    if net_data_target[i][3] == 1:\n",
    "        num.append(3)\n",
    "    if net_data_target[i][4] == 1:\n",
    "        num.append(4)\n",
    "    if net_data_target[i][5] == 1:\n",
    "        num.append(5)\n",
    "    if net_data_target[i][6] == 1:\n",
    "        num.append(6)\n",
    "    if net_data_target[i][7] == 1:\n",
    "        num.append(7)\n",
    "    if net_data_target[i][8] == 1:\n",
    "        num.append(8)\n",
    "    if net_data_target[i][9] == 1:\n",
    "        num.append(9)\n",
    "num = np.asarray(num)        \n",
    "print(type(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c62a6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 397us/sample - loss: 1.6286 - acc: 0.4700\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.7011 - acc: 0.7987\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.5628 - acc: 0.8525\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 299us/sample - loss: 0.4700 - acc: 0.8687\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.4055 - acc: 0.8975\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.3477 - acc: 0.9087\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 290us/sample - loss: 0.2919 - acc: 0.9300\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 279us/sample - loss: 0.2606 - acc: 0.9362\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.2346 - acc: 0.9438\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 279us/sample - loss: 0.2192 - acc: 0.9450\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 0.2012 - acc: 0.9563\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 290us/sample - loss: 0.1859 - acc: 0.9638\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 292us/sample - loss: 0.1738 - acc: 0.9650\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 290us/sample - loss: 0.1652 - acc: 0.9675\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.1661 - acc: 0.9650\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 366us/sample - loss: 0.1518 - acc: 0.9725\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 390us/sample - loss: 0.1341 - acc: 0.9775\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 371us/sample - loss: 0.1257 - acc: 0.9862\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 419us/sample - loss: 0.1180 - acc: 0.9812\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 437us/sample - loss: 0.1098 - acc: 0.9862\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 428us/sample - loss: 0.1068 - acc: 0.9862\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 308us/sample - loss: 0.0991 - acc: 0.9837\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.0922 - acc: 0.9887\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 0.0867 - acc: 0.9912\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 0.0845 - acc: 0.9887\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 291us/sample - loss: 0.0827 - acc: 0.9912\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0763 - acc: 0.9925\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 417us/sample - loss: 0.0739 - acc: 0.9937\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 363us/sample - loss: 0.0677 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.0676 - acc: 0.9950\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 297us/sample - loss: 0.0639 - acc: 0.9962\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.0605 - acc: 0.9962\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.0567 - acc: 0.9962\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 293us/sample - loss: 0.0545 - acc: 0.9962\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 0.0529 - acc: 0.9962\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0517 - acc: 0.9962\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 352us/sample - loss: 0.0485 - acc: 0.9962\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.0457 - acc: 0.9962\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.0444 - acc: 0.9962\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0415 - acc: 0.9962\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0391 - acc: 0.9962\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.0371 - acc: 0.9962\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 301us/sample - loss: 0.0360 - acc: 0.9962\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0348 - acc: 0.9962\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0354 - acc: 0.9962\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 352us/sample - loss: 0.0341 - acc: 0.9962\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 411us/sample - loss: 0.0328 - acc: 0.9962\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 294us/sample - loss: 0.0312 - acc: 0.9975\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 394us/sample - loss: 0.0299 - acc: 0.9975\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0284 - acc: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 input outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 841us/sample - loss: 1.7232 - acc: 0.4613\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 498us/sample - loss: 0.4143 - acc: 0.8888\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 461us/sample - loss: 0.2520 - acc: 0.9388\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 415us/sample - loss: 0.1425 - acc: 0.9750\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 412us/sample - loss: 0.1039 - acc: 0.9837\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 600us/sample - loss: 0.0715 - acc: 0.9900\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 550us/sample - loss: 0.0532 - acc: 0.9937\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 549us/sample - loss: 0.0419 - acc: 0.9962\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 571us/sample - loss: 0.0316 - acc: 0.9962\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 504us/sample - loss: 0.0259 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 485us/sample - loss: 0.0216 - acc: 0.9975\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 450us/sample - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 528us/sample - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 1s 646us/sample - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 551us/sample - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 1s 668us/sample - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 525us/sample - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 442us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 450us/sample - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 448us/sample - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 439us/sample - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 426us/sample - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 441us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 489us/sample - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 427us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 443us/sample - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 407us/sample - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 416us/sample - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 406us/sample - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 474us/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 434us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 453us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 522us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 557us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 541us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 554us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 567us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 484us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 508us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 509us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 464us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 450us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 480us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 464us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 489us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 457us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 473us/sample - loss: 0.0020 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 9 2 6 9 5 4 8 7 1 5 2 6 7 1 5 6 8 1 1 5 9 4 9 4 6 6 9 8 7 0 3 7 3 4 7\n",
      " 6 4 5 4 9 4 4 9 0 3 2 4 8 5 6 7 7 6 1 1 2 4 0 9 2 8 5 9 7 3 8 4 2 3 2 5 8\n",
      " 4 5 4 8 8 5 9 0 4 2 9 8 0 2 5 3 6 1 2 6 5 9 1 6 0 6 4 1 8 4 6 9 7 0 6 4 7\n",
      " 7 1 5 4 9 9 9 0 2 7 5 2 3 6 3 7 2 0 0 6 7 4 4 6 0 0 6 3 7 1 9 2 1 3 0 9 0\n",
      " 7 4 6 5 9 0 9 3 0 1 7 8 8 7 4 4 1 1 3 1 2 9 6 4 5 2 1 7 8 2 5 4 1 1 6 5 8\n",
      " 5 1 1 2 0 7 4 2 6 0 2 3 9 3 3]\n",
      "accuracy is 0.93\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 414us/sample - loss: 1.8528 - acc: 0.4512\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.8466 - acc: 0.7763\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 283us/sample - loss: 0.6066 - acc: 0.8450\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 298us/sample - loss: 0.4691 - acc: 0.8913\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.3862 - acc: 0.8963\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.3373 - acc: 0.9200\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 293us/sample - loss: 0.2951 - acc: 0.9463\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.2692 - acc: 0.9488\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.2407 - acc: 0.9500\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.2179 - acc: 0.9588\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.2038 - acc: 0.9575\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.1890 - acc: 0.9575\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1706 - acc: 0.9712\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.1539 - acc: 0.9775\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.1496 - acc: 0.9812\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.1402 - acc: 0.9800\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.1252 - acc: 0.9825\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1190 - acc: 0.9787\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.1130 - acc: 0.9850\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.1086 - acc: 0.9862\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.1005 - acc: 0.9850\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0908 - acc: 0.9875\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0854 - acc: 0.9900\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0825 - acc: 0.9900\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0774 - acc: 0.9875\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0747 - acc: 0.9887\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0680 - acc: 0.9912\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0647 - acc: 0.9925\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.0603 - acc: 0.9950\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0572 - acc: 0.9950\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0541 - acc: 0.9962\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0508 - acc: 0.9962\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0487 - acc: 0.9962\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0471 - acc: 0.9962\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0453 - acc: 0.9962\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0432 - acc: 0.9962\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 301us/sample - loss: 0.0413 - acc: 0.9962\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0397 - acc: 0.9962\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0383 - acc: 0.9962\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0379 - acc: 0.9962\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.0364 - acc: 0.9962\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0350 - acc: 0.9962\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 313us/sample - loss: 0.0341 - acc: 0.9962\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0336 - acc: 0.9962\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 327us/sample - loss: 0.0324 - acc: 0.9962\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0318 - acc: 0.9962\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0309 - acc: 0.9962\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 335us/sample - loss: 0.0302 - acc: 0.9962\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 330us/sample - loss: 0.0290 - acc: 0.9962\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0284 - acc: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 input outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 555us/sample - loss: 1.3730 - acc: 0.5625\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 428us/sample - loss: 0.3587 - acc: 0.8963\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 411us/sample - loss: 0.1778 - acc: 0.9588\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 394us/sample - loss: 0.1064 - acc: 0.9800\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 407us/sample - loss: 0.0616 - acc: 0.9937\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 490us/sample - loss: 0.0422 - acc: 0.9975\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 391us/sample - loss: 0.0287 - acc: 0.9987\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 395us/sample - loss: 0.0220 - acc: 0.9987\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 507us/sample - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 478us/sample - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 536us/sample - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 466us/sample - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 567us/sample - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 463us/sample - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 398us/sample - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 394us/sample - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 372us/sample - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 384us/sample - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 360us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 464us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 514us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 392us/sample - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 391us/sample - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 408us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 458us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 468us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 408us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 518us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 480us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 450us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 510us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 494us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 574us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 501us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 442us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 405us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 395us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 414us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 431us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 415us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 479us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 494us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 446us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 407us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 459us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 477us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 454us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 452us/sample - loss: 0.0016 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 1 8 2 9 3 3 3 9 9 1 4 3 6 5 3 7 7 0 0 4 5 5 3 3 1 0 5 3 2 8 0 8 6 4 9\n",
      " 4 6 6 4 5 9 9 0 9 1 7 7 5 4 8 7 3 0 1 9 1 6 4 0 9 3 6 0 6 6 1 6 5 3 1 9 2\n",
      " 2 2 5 3 8 7 7 5 2 2 5 3 2 4 3 7 8 8 7 4 7 9 0 1 3 4 5 0 4 6 7 3 0 7 9 8 1\n",
      " 9 5 3 5 5 3 3 4 8 0 9 2 0 4 7 6 8 9 0 4 6 3 9 6 2 1 3 4 8 3 6 2 1 7 0 9 5\n",
      " 6 2 3 3 5 3 2 3 4 0 9 2 7 9 5 7 9 4 6 9 1 7 0 3 4 7 5 3 4 9 7 4 5 6 1 5 3\n",
      " 4 5 5 7 3 1 2 6 2 6 2 0 9 3 8]\n",
      "accuracy is 0.895\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 418us/sample - loss: 1.6620 - acc: 0.4688\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.6979 - acc: 0.8112\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.5077 - acc: 0.8725\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.3932 - acc: 0.8963\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.3235 - acc: 0.9275\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.2784 - acc: 0.9388\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 275us/sample - loss: 0.2314 - acc: 0.9513\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.2087 - acc: 0.9575\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 316us/sample - loss: 0.1910 - acc: 0.9638\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 313us/sample - loss: 0.1751 - acc: 0.9675\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 307us/sample - loss: 0.1516 - acc: 0.9712\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.1365 - acc: 0.9700\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.1212 - acc: 0.9800\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 317us/sample - loss: 0.1100 - acc: 0.9862\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.1010 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0941 - acc: 0.9850\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 297us/sample - loss: 0.0872 - acc: 0.9900\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0812 - acc: 0.9900\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.0737 - acc: 0.9925\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0668 - acc: 0.9937\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0653 - acc: 0.9912\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0617 - acc: 0.9925\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 294us/sample - loss: 0.0590 - acc: 0.9937\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0544 - acc: 0.9937\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0513 - acc: 0.9962\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.0489 - acc: 0.9962\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0479 - acc: 0.9950\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 286us/sample - loss: 0.0459 - acc: 0.9962\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0430 - acc: 0.9975\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0406 - acc: 0.9975\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0383 - acc: 0.9975\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0379 - acc: 0.9975\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0347 - acc: 0.9987\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0332 - acc: 0.9987\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0318 - acc: 0.9975\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0295 - acc: 0.9987\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0283 - acc: 0.9987\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0270 - acc: 0.9987\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 319us/sample - loss: 0.0265 - acc: 0.9987\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 298us/sample - loss: 0.0259 - acc: 0.9987\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 294us/sample - loss: 0.0249 - acc: 0.9987\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0240 - acc: 0.9987\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 297us/sample - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 292us/sample - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 283us/sample - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0193 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 input outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 560us/sample - loss: 1.4113 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 414us/sample - loss: 0.3008 - acc: 0.9287\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 417us/sample - loss: 0.1634 - acc: 0.9650\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 396us/sample - loss: 0.0957 - acc: 0.9825\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 425us/sample - loss: 0.0641 - acc: 0.9912\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 427us/sample - loss: 0.0428 - acc: 0.9962\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 444us/sample - loss: 0.0306 - acc: 0.9975\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 406us/sample - loss: 0.0231 - acc: 0.9987\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0189 - acc: 0.9987\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 430us/sample - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 420us/sample - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 493us/sample - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 468us/sample - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 417us/sample - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 430us/sample - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 427us/sample - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 428us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 436us/sample - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 434us/sample - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 433us/sample - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 404us/sample - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 440us/sample - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 415us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 433us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 426us/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 447us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 418us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 378us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 448us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 405us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 410us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 420us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 426us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 443us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 418us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 462us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 433us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 452us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 438us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 413us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 400us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 404us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 400us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 399us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 410us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 422us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 417us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 434us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 424us/sample - loss: 0.0013 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 1 4 5 7 9 6 2 5 6 2 7 4 3 0 5 0 4 9 7 7 3 7 5 6 4 1 2 5 9 5 0 2 3 7 8\n",
      " 4 2 2 0 0 4 8 8 8 5 9 5 2 9 9 5 4 5 9 0 7 1 0 4 6 7 8 8 2 7 7 7 3 7 6 3 4\n",
      " 1 9 7 0 0 2 2 2 2 0 3 9 1 5 5 0 0 2 6 2 2 0 6 5 4 8 8 3 8 0 3 5 8 4 3 1 6\n",
      " 9 7 7 5 1 4 8 7 8 0 2 7 9 5 1 8 8 1 4 2 6 1 9 9 8 1 7 9 4 5 5 4 4 9 6 2 0\n",
      " 1 8 2 1 1 7 8 6 6 0 9 7 6 8 1 3 5 7 4 0 8 6 0 6 3 7 9 8 7 9 4 6 6 2 6 1 9\n",
      " 2 3 3 7 5 1 9 5 4 2 8 2 6 3 8]\n",
      "accuracy is 0.92\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 419us/sample - loss: 1.8694 - acc: 0.4062\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.8242 - acc: 0.7763\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.6261 - acc: 0.8550\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.5214 - acc: 0.8687\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.4382 - acc: 0.9050\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.3809 - acc: 0.9075\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.3538 - acc: 0.9175\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.3308 - acc: 0.9300\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.2887 - acc: 0.9463\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.2572 - acc: 0.9475\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.2395 - acc: 0.9513\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.2188 - acc: 0.9550\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.2060 - acc: 0.9563\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.1958 - acc: 0.9550\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.1829 - acc: 0.9588\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.1722 - acc: 0.9638\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.1550 - acc: 0.9688\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.1475 - acc: 0.9675\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.1367 - acc: 0.9688\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.1229 - acc: 0.9750\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.1143 - acc: 0.9775\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.1076 - acc: 0.9800\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.1023 - acc: 0.9800\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0996 - acc: 0.9787\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0932 - acc: 0.9800\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0900 - acc: 0.9800\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0848 - acc: 0.9825\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0800 - acc: 0.9825\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0755 - acc: 0.9850\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0717 - acc: 0.9862\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0695 - acc: 0.9850\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0679 - acc: 0.9862\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0661 - acc: 0.9862\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0614 - acc: 0.9887\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0601 - acc: 0.9900\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.0579 - acc: 0.9887\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0546 - acc: 0.9912\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0532 - acc: 0.9912\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.0517 - acc: 0.9912\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0500 - acc: 0.9912\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0484 - acc: 0.9925\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0471 - acc: 0.9925\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0455 - acc: 0.9950\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0443 - acc: 0.9950\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.0436 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 310us/sample - loss: 0.0422 - acc: 0.9962\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0413 - acc: 0.9975\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 0.0401 - acc: 0.9975\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0393 - acc: 0.9975\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.0385 - acc: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 input outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 555us/sample - loss: 1.5782 - acc: 0.4787\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 420us/sample - loss: 0.4397 - acc: 0.8838\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 402us/sample - loss: 0.2727 - acc: 0.9312\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 434us/sample - loss: 0.1744 - acc: 0.9638\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 406us/sample - loss: 0.1209 - acc: 0.9800\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 414us/sample - loss: 0.0853 - acc: 0.9912\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 413us/sample - loss: 0.0631 - acc: 0.9937\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 430us/sample - loss: 0.0492 - acc: 0.9950\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 426us/sample - loss: 0.0370 - acc: 0.9975\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 413us/sample - loss: 0.0309 - acc: 0.9987\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 443us/sample - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 424us/sample - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 416us/sample - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 429us/sample - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 435us/sample - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 427us/sample - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 421us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 435us/sample - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 430us/sample - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 405us/sample - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 440us/sample - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 403us/sample - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 420us/sample - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 389us/sample - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 409us/sample - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 414us/sample - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 413us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 420us/sample - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 446us/sample - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 453us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 448us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 436us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 436us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 432us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 436us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 441us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 454us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 446us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 432us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 388us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 396us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 393us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 391us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 408us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 404us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 409us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 399us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 386us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 412us/sample - loss: 0.0023 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 3 7 2 6 0 2 8 5 1 7 8 6 3 1 3 1 3 5 5 0 8 7 5 9 9 2 5 6 5 7 6 3 8 6\n",
      " 7 2 0 0 1 7 2 5 3 7 1 1 1 3 9 9 5 2 6 6 8 4 5 3 7 0 0 1 7 9 1 3 6 4 6 6 3\n",
      " 5 4 2 9 2 9 6 3 2 7 6 0 1 2 5 0 0 7 6 2 8 5 3 8 8 8 4 4 4 6 0 8 8 9 9 3 4\n",
      " 8 7 9 0 4 1 1 4 8 8 3 4 4 3 6 7 7 3 6 3 9 1 1 7 6 7 0 0 3 8 3 0 5 1 1 2 1\n",
      " 8 3 6 7 2 1 7 5 0 7 9 7 1 0 8 2 3 6 3 6 4 2 6 6 1 9 3 6 9 4 7 4 2 4 0 8 5\n",
      " 8 9 8 1 1 1 9 6 4 0 6 8 8 7 8]\n",
      "accuracy is 0.945\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 mydata\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 382us/sample - loss: 1.6198 - acc: 0.4812\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.7022 - acc: 0.7925\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.5339 - acc: 0.8575\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.4247 - acc: 0.8863\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.3492 - acc: 0.9025\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.3056 - acc: 0.9275\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.2691 - acc: 0.9362\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.2376 - acc: 0.9400\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.2189 - acc: 0.9438\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.1966 - acc: 0.9575\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.1880 - acc: 0.9600\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1672 - acc: 0.9650\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.1454 - acc: 0.9737\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.1388 - acc: 0.9712\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.1283 - acc: 0.9800\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.1247 - acc: 0.9750\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.1156 - acc: 0.9800\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1071 - acc: 0.9812\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.1004 - acc: 0.9837\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0931 - acc: 0.9862\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0845 - acc: 0.9862\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0786 - acc: 0.9900\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0755 - acc: 0.9900\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0710 - acc: 0.9912\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0672 - acc: 0.9887\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0653 - acc: 0.9925\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0624 - acc: 0.9887\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0604 - acc: 0.9900\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0590 - acc: 0.9912\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0536 - acc: 0.9937\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0508 - acc: 0.9925\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0505 - acc: 0.9912\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0515 - acc: 0.9950\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0464 - acc: 0.9962\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0463 - acc: 0.9950\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0432 - acc: 0.9962\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.0412 - acc: 0.9950\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.0402 - acc: 0.9937\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 279us/sample - loss: 0.0396 - acc: 0.9962\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0380 - acc: 0.9962\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0361 - acc: 0.9962\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.0347 - acc: 0.9962\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.0342 - acc: 0.9975\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.0330 - acc: 0.9975\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.0324 - acc: 0.9975\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 287us/sample - loss: 0.0318 - acc: 0.9975\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 290us/sample - loss: 0.0305 - acc: 0.9987\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 310us/sample - loss: 0.0292 - acc: 0.9987\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.0285 - acc: 0.9987\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.0275 - acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 input outputs\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 566us/sample - loss: 1.3058 - acc: 0.5987\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 455us/sample - loss: 0.3104 - acc: 0.9175\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.1764 - acc: 0.9538\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 439us/sample - loss: 0.1136 - acc: 0.9800\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 431us/sample - loss: 0.0725 - acc: 0.9875\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 450us/sample - loss: 0.0515 - acc: 0.9950\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 443us/sample - loss: 0.0340 - acc: 0.9975\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 461us/sample - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 476us/sample - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 462us/sample - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 434us/sample - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 458us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 457us/sample - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 437us/sample - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 444us/sample - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 455us/sample - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 445us/sample - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 447us/sample - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 419us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 439us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 444us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 410us/sample - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 412us/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 428us/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 423us/sample - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 419us/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 432us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 438us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 430us/sample - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 472us/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 469us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 465us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 465us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 455us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 437us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 482us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 480us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 469us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 444us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 464us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 471us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 476us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 422us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 451us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 425us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 442us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 437us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 427us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 416us/sample - loss: 0.0016 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 1 8 0 6 9 9 2 0 3 6 7 1 3 3 5 8 0 5 7 2 3 9 0 5 7 2 5 2 3 8 5 8 0 8\n",
      " 9 8 7 9 8 7 5 0 5 1 7 3 1 6 3 6 5 6 9 2 5 1 3 6 2 9 1 4 8 7 8 0 5 2 7 4 0\n",
      " 2 9 0 2 2 7 5 8 8 2 2 9 6 9 4 2 0 0 5 7 3 9 1 8 5 1 1 9 0 4 2 0 1 4 0 1 2\n",
      " 2 8 0 0 1 6 5 4 4 4 8 1 5 8 8 1 4 8 8 3 9 0 7 4 8 4 2 2 5 8 1 3 9 1 0 3 0\n",
      " 8 3 4 9 2 4 0 6 8 0 2 9 9 5 7 1 7 2 3 5 7 5 1 8 5 0 1 2 1 5 1 4 8 4 0 2 9\n",
      " 0 0 1 6 0 6 8 5 8 3 4 8 6 3 5]\n",
      "accuracy is 0.915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5)\n",
    "acc_per_fold = []\n",
    "acc = []\n",
    "loss = []\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(net_data_input, net_data_target, net_mydata_input):\n",
    "\n",
    "  \n",
    "  # Define the model architecture for net mydata\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='tanh', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Generate a print\n",
    "    # Fit data to model\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} mydata')\n",
    "    history_mydata = model.fit(net_mydata_input[train], net_data_target[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    \n",
    "\n",
    "    \n",
    "    predictions_mydata_train = model.predict(net_mydata_input[train])\n",
    "    classes_mydata_train = np.argmax(predictions_mydata_train, axis = 1)\n",
    "    classes_mydata_train = tf.keras.utils.to_categorical(classes_mydata_train,10)\n",
    "\n",
    "    predictions_mydata_test = model.predict(net_mydata_input[test])\n",
    "    classes_mydata_test = np.argmax(predictions_mydata_test, axis = 1)\n",
    "    classes_mydata_test = tf.keras.utils.to_categorical(classes_mydata_test,10)\n",
    "    \n",
    "    \n",
    "\n",
    "    #make train list input\n",
    "    joined_list_train = []\n",
    "    joined_list_test = []\n",
    "\n",
    "    for i in range(800):\n",
    "        b = [*net_data_input[train][i][0], *classes_mydata_train[i]]\n",
    "        joined_list_train.append(b)\n",
    "        \n",
    "    for j in range(200):\n",
    "        a = [*net_data_input[test][j][0], *classes_mydata_test[j]]\n",
    "        joined_list_test.append(a)\n",
    "\n",
    "    joined_list_train = np.asarray(joined_list_train)\n",
    "    joined_list_test = np.asarray(joined_list_test)\n",
    "    \n",
    "    \n",
    "    joined_list_train = joined_list_train.reshape(joined_list_train.shape[0],794,1)\n",
    "\n",
    "    joined_list_test = joined_list_test.reshape(joined_list_test.shape[0],794,1)\n",
    "    \n",
    "  # Define the model architecture for net data\n",
    "\n",
    "    cnn_model_outputs = Sequential()\n",
    "    #rnn_model.add(Flatten())\n",
    "    cnn_model_outputs.add(Conv1D(32, 3, activation='relu', kernel_initializer='he_uniform'))\n",
    "    cnn_model_outputs.add(MaxPooling1D((2)))\n",
    "    #rnn_model.add(SimpleRNN(128,input_shape=xtrain[0].shape,return_sequences=True))\n",
    "    #rnn_model.add(SimpleRNN(128))\n",
    "    cnn_model_outputs.add(Flatten())\n",
    "    cnn_model_outputs.add(Dense(100, activation='tanh', kernel_initializer='he_uniform'))\n",
    "    cnn_model_outputs.add(Dense(10, activation='softmax'))\n",
    "\n",
    "  # Compile the model\n",
    "    cnn_model_outputs.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} input outputs')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = cnn_model_outputs.fit(joined_list_train, net_data_target[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "    tf.keras.utils.plot_model(cnn_model_outputs, to_file='combination1_cnn.png', show_shapes=True, show_layer_names=True)\n",
    "    scores = cnn_model_outputs.evaluate(joined_list_test, net_data_target[test], verbose=0)\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    predictions = cnn_model_outputs.predict(joined_list_test)\n",
    "    classes = np.argmax(predictions, axis = 1)\n",
    "    print(num[test])\n",
    "    acc_per_fold.append(accuracy_score(num[test],classes))\n",
    "    \n",
    "    print('accuracy is ' + str(accuracy_score(num[test],classes)))\n",
    "    \n",
    "  # Generate generalization metrics\n",
    "    acc.append(history.history['acc'])\n",
    "    loss.append(history.history['loss'])\n",
    "    \n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652ec34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           multiple                  128       \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  multiple                 0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            multiple                  1267300   \n",
      "                                                                 \n",
      " dense_39 (Dense)            multiple                  1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,268,438\n",
      "Trainable params: 1,268,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model_outputs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db3cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.33284981509204953 - Accuracy: 0.92%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.48594063729047776 - Accuracy: 0.91%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.2576835812628269 - Accuracy: 0.93%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.27227417171001433 - Accuracy: 0.935%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.3523292350769043 - Accuracy: 0.915%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.922 (+- 0.009273618495495713)\n",
      "> Loss: 0.3402154880864546\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafc40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CNN_both_input_output_cross_validation_acc.csv',acc, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57e9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a42910",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CNN__both_input_output_cross_validation_loss.csv',loss, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390ab36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
