{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7595f7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551f828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Conv2D,MaxPooling2D\n",
    "from keras.layers import LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e060759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = open(\"mydata_shuffle_input.csv\")\n",
    "inputs = np.genfromtxt(a, delimiter=\",\")\n",
    "inputs = inputs.reshape(inputs.shape[0],28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d0d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open(\"mydata_shuffle_target.csv\")\n",
    "targets = np.genfromtxt(c, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5cd850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_input = []\n",
    "\n",
    "train_label = []\n",
    "\n",
    "for i in range(800):\n",
    "    \n",
    "    train_input.append(list(inputs[i]))\n",
    "    \n",
    "    train_label.append(targets[i])\n",
    "\n",
    "    \n",
    "test_input = []\n",
    "\n",
    "test_label = []\n",
    "\n",
    "for i in range(800,1000):\n",
    "    \n",
    "    test_input.append(list(inputs[i]))\n",
    "    \n",
    "    test_label.append(targets[i])\n",
    "#train_informations = train_informations/100\n",
    "\n",
    "#test_informations = test_informations/100\n",
    "\n",
    "train_input = np.asarray(train_input)\n",
    "test_input = np.asarray(test_input)\n",
    "train_label = np.asarray(train_label)\n",
    "test_label = np.asarray(test_label)\n",
    "\n",
    "xtrain = train_input.reshape(train_input.shape[0],28,28,1)\n",
    "\n",
    "xtest = test_input.reshape(test_input.shape[0],28,28,1)\n",
    "\n",
    "ytrain = train_label\n",
    "\n",
    "ytest = test_label\n",
    "\n",
    "print(ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f70427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for i in range(len(targets)):\n",
    "    if targets[i][0] == 1:\n",
    "        num.append(0)\n",
    "    if targets[i][1] == 1:\n",
    "        num.append(1)\n",
    "    if targets[i][2] == 1:\n",
    "        num.append(2)\n",
    "    if targets[i][3] == 1:\n",
    "        num.append(3)\n",
    "    if targets[i][4] == 1:\n",
    "        num.append(4)\n",
    "    if targets[i][5] == 1:\n",
    "        num.append(5)\n",
    "    if targets[i][6] == 1:\n",
    "        num.append(6)\n",
    "    if targets[i][7] == 1:\n",
    "        num.append(7)\n",
    "    if targets[i][8] == 1:\n",
    "        num.append(8)\n",
    "    if targets[i][9] == 1:\n",
    "        num.append(9)\n",
    "num = np.asarray(num)        \n",
    "print(type(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469cb82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 364us/sample - loss: 1.6136 - acc: 0.4975\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 223us/sample - loss: 0.7530 - acc: 0.7950\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.5853 - acc: 0.8263\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.4576 - acc: 0.8825\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.4047 - acc: 0.9050\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.3633 - acc: 0.9187\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 333us/sample - loss: 0.3197 - acc: 0.9312\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 296us/sample - loss: 0.2906 - acc: 0.9325\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.2580 - acc: 0.9438\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.2264 - acc: 0.9475\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.2162 - acc: 0.9500\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.2028 - acc: 0.9550\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1880 - acc: 0.9538\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.1673 - acc: 0.9675\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1597 - acc: 0.9700\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 0.1559 - acc: 0.9675\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.1451 - acc: 0.9725\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.1325 - acc: 0.9737\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 1s 639us/sample - loss: 0.1221 - acc: 0.9725\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 326us/sample - loss: 0.1116 - acc: 0.9762\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 358us/sample - loss: 0.1015 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 322us/sample - loss: 0.0964 - acc: 0.9825\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 304us/sample - loss: 0.0910 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.0877 - acc: 0.9850\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0854 - acc: 0.9825\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0830 - acc: 0.9825\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0822 - acc: 0.9812\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.0768 - acc: 0.9837\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 323us/sample - loss: 0.0737 - acc: 0.9850\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.0708 - acc: 0.9862\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 303us/sample - loss: 0.0663 - acc: 0.9875\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0631 - acc: 0.9887\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 0.0596 - acc: 0.9900\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0592 - acc: 0.9900\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0585 - acc: 0.9887\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0550 - acc: 0.9900\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0543 - acc: 0.9912\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0526 - acc: 0.9925\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0511 - acc: 0.9937\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.0506 - acc: 0.9937\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 441us/sample - loss: 0.0478 - acc: 0.9962\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0475 - acc: 0.9962\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.0454 - acc: 0.9962\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0439 - acc: 0.9975\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0415 - acc: 0.9975\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.0407 - acc: 0.9975\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0385 - acc: 0.9975\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0371 - acc: 0.9975\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0360 - acc: 0.9975\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0352 - acc: 0.9975\n",
      "[1 3 9 2 6 9 5 4 8 7 1 5 2 6 7 1 5 6 8 1 1 5 9 4 9 4 6 6 9 8 7 0 3 7 3 4 7\n",
      " 6 4 5 4 9 4 4 9 0 3 2 4 8 5 6 7 7 6 1 1 2 4 0 9 2 8 5 9 7 3 8 4 2 3 2 5 8\n",
      " 4 5 4 8 8 5 9 0 4 2 9 8 0 2 5 3 6 1 2 6 5 9 1 6 0 6 4 1 8 4 6 9 7 0 6 4 7\n",
      " 7 1 5 4 9 9 9 0 2 7 5 2 3 6 3 7 2 0 0 6 7 4 4 6 0 0 6 3 7 1 9 2 1 3 0 9 0\n",
      " 7 4 6 5 9 0 9 3 0 1 7 8 8 7 4 4 1 1 3 1 2 9 6 4 5 2 1 7 8 2 5 4 1 1 6 5 8\n",
      " 5 1 1 2 0 7 4 2 6 0 2 3 9 3 3]\n",
      "accuracy is 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 303us/sample - loss: 1.7467 - acc: 0.4412\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.7046 - acc: 0.7962\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.5355 - acc: 0.8450\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.4770 - acc: 0.8750\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.4082 - acc: 0.9000\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.3427 - acc: 0.9237\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.2944 - acc: 0.9287\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 0.2680 - acc: 0.9400\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 261us/sample - loss: 0.2418 - acc: 0.9500\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.2183 - acc: 0.9638\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.1978 - acc: 0.9663\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.1823 - acc: 0.9663\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.1661 - acc: 0.9663\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.1517 - acc: 0.9737\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.1401 - acc: 0.9800\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.1297 - acc: 0.9837\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.1214 - acc: 0.9837\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.1063 - acc: 0.9825\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0977 - acc: 0.9862\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0942 - acc: 0.9887\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.0921 - acc: 0.9875\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0846 - acc: 0.9875\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0797 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0742 - acc: 0.9900\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0696 - acc: 0.9912\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0647 - acc: 0.9937\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0610 - acc: 0.9925\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.0574 - acc: 0.9925\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0552 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0515 - acc: 0.9937\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.0495 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0472 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0446 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0430 - acc: 0.9950\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.0409 - acc: 0.9950\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0396 - acc: 0.9975\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0381 - acc: 0.9975\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0374 - acc: 0.9975\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.0381 - acc: 0.9975\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0370 - acc: 0.9975\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0349 - acc: 0.9975\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.0331 - acc: 0.9975\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0321 - acc: 0.9975\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0311 - acc: 0.9975\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0300 - acc: 0.9975\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.0292 - acc: 0.9975\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.0286 - acc: 0.9975\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.0278 - acc: 0.9975\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0272 - acc: 0.9975\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.0265 - acc: 0.9975\n",
      "[8 4 1 8 2 9 3 3 3 9 9 1 4 3 6 5 3 7 7 0 0 4 5 5 3 3 1 0 5 3 2 8 0 8 6 4 9\n",
      " 4 6 6 4 5 9 9 0 9 1 7 7 5 4 8 7 3 0 1 9 1 6 4 0 9 3 6 0 6 6 1 6 5 3 1 9 2\n",
      " 2 2 5 3 8 7 7 5 2 2 5 3 2 4 3 7 8 8 7 4 7 9 0 1 3 4 5 0 4 6 7 3 0 7 9 8 1\n",
      " 9 5 3 5 5 3 3 4 8 0 9 2 0 4 7 6 8 9 0 4 6 3 9 6 2 1 3 4 8 3 6 2 1 7 0 9 5\n",
      " 6 2 3 3 5 3 2 3 4 0 9 2 7 9 5 7 9 4 6 9 1 7 0 3 4 7 5 3 4 9 7 4 5 6 1 5 3\n",
      " 4 5 5 7 3 1 2 6 2 6 2 0 9 3 8]\n",
      "accuracy is 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 1.6159 - acc: 0.4913\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.6681 - acc: 0.8037\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.5124 - acc: 0.8662\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.4404 - acc: 0.8838\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.3659 - acc: 0.9025\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.3336 - acc: 0.9125\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.2761 - acc: 0.9375\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.2560 - acc: 0.9400\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.2281 - acc: 0.9500\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.2150 - acc: 0.9575\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.1936 - acc: 0.9625\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.1743 - acc: 0.9688\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1617 - acc: 0.9700\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1475 - acc: 0.9725\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.1305 - acc: 0.9775\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.1204 - acc: 0.9837\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1101 - acc: 0.9800\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1033 - acc: 0.9812\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0965 - acc: 0.9812\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0908 - acc: 0.9837\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0843 - acc: 0.9837\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0796 - acc: 0.9862\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0746 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0712 - acc: 0.9875\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0681 - acc: 0.9862\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0644 - acc: 0.9875\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.0609 - acc: 0.9875\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0578 - acc: 0.9875\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0561 - acc: 0.9875\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0534 - acc: 0.9900\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0515 - acc: 0.9925\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.0500 - acc: 0.9925\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0479 - acc: 0.9925\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0474 - acc: 0.9912\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0451 - acc: 0.9925\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0438 - acc: 0.9925\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.0428 - acc: 0.9937\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0420 - acc: 0.9937\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0409 - acc: 0.9950\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0399 - acc: 0.9950\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.0386 - acc: 0.9950\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0375 - acc: 0.9950\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.0365 - acc: 0.9937\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0354 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0342 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0338 - acc: 0.9937\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0322 - acc: 0.9937\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0314 - acc: 0.9950\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0305 - acc: 0.9950\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0298 - acc: 0.9950\n",
      "[9 4 1 4 5 7 9 6 2 5 6 2 7 4 3 0 5 0 4 9 7 7 3 7 5 6 4 1 2 5 9 5 0 2 3 7 8\n",
      " 4 2 2 0 0 4 8 8 8 5 9 5 2 9 9 5 4 5 9 0 7 1 0 4 6 7 8 8 2 7 7 7 3 7 6 3 4\n",
      " 1 9 7 0 0 2 2 2 2 0 3 9 1 5 5 0 0 2 6 2 2 0 6 5 4 8 8 3 8 0 3 5 8 4 3 1 6\n",
      " 9 7 7 5 1 4 8 7 8 0 2 7 9 5 1 8 8 1 4 2 6 1 9 9 8 1 7 9 4 5 5 4 4 9 6 2 0\n",
      " 1 8 2 1 1 7 8 6 6 0 9 7 6 8 1 3 5 7 4 0 8 6 0 6 3 7 9 8 7 9 4 6 6 2 6 1 9\n",
      " 2 3 3 7 5 1 9 5 4 2 8 2 6 3 8]\n",
      "accuracy is 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 303us/sample - loss: 1.6556 - acc: 0.4787\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.7264 - acc: 0.7775\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.5619 - acc: 0.8413\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.4712 - acc: 0.8750\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.3983 - acc: 0.8863\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 275us/sample - loss: 0.3467 - acc: 0.9038\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.2918 - acc: 0.9237\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.2623 - acc: 0.9350\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.2391 - acc: 0.9375\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.2242 - acc: 0.9500\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.2006 - acc: 0.9575\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 0.1965 - acc: 0.9600\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1781 - acc: 0.9638\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1585 - acc: 0.9737\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1446 - acc: 0.9712\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.1386 - acc: 0.9650\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1316 - acc: 0.9750\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.1295 - acc: 0.9800\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.1243 - acc: 0.9800\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.1218 - acc: 0.9800\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1110 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1030 - acc: 0.9800\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.0933 - acc: 0.9800\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0899 - acc: 0.9825\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.0847 - acc: 0.9850\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0811 - acc: 0.9887\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0757 - acc: 0.9887\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0738 - acc: 0.9862\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0730 - acc: 0.9875\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.0673 - acc: 0.9900\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0610 - acc: 0.9912\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0626 - acc: 0.9887\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0604 - acc: 0.9912\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0582 - acc: 0.9912\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0566 - acc: 0.9912\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0539 - acc: 0.9925\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.0509 - acc: 0.9925\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0480 - acc: 0.9925\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0461 - acc: 0.9925\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.0442 - acc: 0.9925\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.0427 - acc: 0.9925\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.0413 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 234us/sample - loss: 0.0399 - acc: 0.9925\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0390 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0376 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0371 - acc: 0.9950\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0358 - acc: 0.9950\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.0355 - acc: 0.9950\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0360 - acc: 0.9950\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0358 - acc: 0.9950\n",
      "[1 0 2 3 7 2 6 0 2 8 5 1 7 8 6 3 1 3 1 3 5 5 0 8 7 5 9 9 2 5 6 5 7 6 3 8 6\n",
      " 7 2 0 0 1 7 2 5 3 7 1 1 1 3 9 9 5 2 6 6 8 4 5 3 7 0 0 1 7 9 1 3 6 4 6 6 3\n",
      " 5 4 2 9 2 9 6 3 2 7 6 0 1 2 5 0 0 7 6 2 8 5 3 8 8 8 4 4 4 6 0 8 8 9 9 3 4\n",
      " 8 7 9 0 4 1 1 4 8 8 3 4 4 3 6 7 7 3 6 3 9 1 1 7 6 7 0 0 3 8 3 0 5 1 1 2 1\n",
      " 8 3 6 7 2 1 7 5 0 7 9 7 1 0 8 2 3 6 3 6 4 2 6 6 1 9 3 6 9 4 7 4 2 4 0 8 5\n",
      " 8 9 8 1 1 1 9 6 4 0 6 8 8 7 8]\n",
      "accuracy is 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 296us/sample - loss: 1.8758 - acc: 0.4075\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.8455 - acc: 0.7775\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.6581 - acc: 0.8300\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.5378 - acc: 0.8675\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.4630 - acc: 0.8900\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.3906 - acc: 0.9038\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.3457 - acc: 0.9212\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.2997 - acc: 0.9388\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.2671 - acc: 0.9413\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.2472 - acc: 0.9500\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.2307 - acc: 0.9525\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.2038 - acc: 0.9625\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.1896 - acc: 0.9625\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1884 - acc: 0.9525\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.1712 - acc: 0.9638\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.1501 - acc: 0.9675\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1395 - acc: 0.9750\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1386 - acc: 0.9737\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1284 - acc: 0.9750\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.1225 - acc: 0.9775\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1181 - acc: 0.9775\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.1120 - acc: 0.9775\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1027 - acc: 0.9825\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.0965 - acc: 0.9837\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.0907 - acc: 0.9862\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.0852 - acc: 0.9887\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 271us/sample - loss: 0.0809 - acc: 0.9887\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0789 - acc: 0.9887\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0762 - acc: 0.9875\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.0725 - acc: 0.9862\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0677 - acc: 0.9862\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.0650 - acc: 0.9862\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0624 - acc: 0.9887\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0626 - acc: 0.9912\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0631 - acc: 0.9912\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0590 - acc: 0.9925\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0566 - acc: 0.9925\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0554 - acc: 0.9925\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0538 - acc: 0.9912\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0507 - acc: 0.9912\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.0492 - acc: 0.9937\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0497 - acc: 0.9925\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.0470 - acc: 0.9925\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 235us/sample - loss: 0.0451 - acc: 0.9950\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.0436 - acc: 0.9962\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.0418 - acc: 0.9987\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.0402 - acc: 0.9987\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.0388 - acc: 0.9987\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.0375 - acc: 0.9975\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.0359 - acc: 0.9987\n",
      "[6 6 6 1 8 0 6 9 9 2 0 3 6 7 1 3 3 5 8 0 5 7 2 3 9 0 5 7 2 5 2 3 8 5 8 0 8\n",
      " 9 8 7 9 8 7 5 0 5 1 7 3 1 6 3 6 5 6 9 2 5 1 3 6 2 9 1 4 8 7 8 0 5 2 7 4 0\n",
      " 2 9 0 2 2 7 5 8 8 2 2 9 6 9 4 2 0 0 5 7 3 9 1 8 5 1 1 9 0 4 2 0 1 4 0 1 2\n",
      " 2 8 0 0 1 6 5 4 4 4 8 1 5 8 8 1 4 8 8 3 9 0 7 4 8 4 2 2 5 8 1 3 9 1 0 3 0\n",
      " 8 3 4 9 2 4 0 6 8 0 2 9 9 5 7 1 7 2 3 5 7 5 1 8 5 0 1 2 1 5 1 4 8 4 0 2 9\n",
      " 0 0 1 6 0 6 8 5 8 3 4 8 6 3 5]\n",
      "accuracy is 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "acc = []\n",
    "loss = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets, num):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='tanh', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    predictions = model.predict(inputs[test])\n",
    "    classes = np.argmax(predictions, axis = 1)\n",
    "    print(num[test])\n",
    "    acc_per_fold.append(accuracy_score(num[test],classes))\n",
    "    \n",
    "    print('accuracy is ' + str(accuracy_score(num[test],classes)))\n",
    "    \n",
    "  # Generate generalization metrics\n",
    "    acc.append(history.history['acc'])\n",
    "    loss.append(history.history['loss'])\n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33dd5b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.304042621254921 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.3318784338235855 - Accuracy: 0.905%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.25432632058858873 - Accuracy: 0.92%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.2697135519981384 - Accuracy: 0.925%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.38117236375808716 - Accuracy: 0.91%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9110000000000001 (+- 0.01067707825203132)\n",
      "> Loss: 0.30822665828466417\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9853b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4956beb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch,history.history['acc'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67d304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt('CNNmydata_cross_validation_acc.csv',acc, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5524b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CNNmydata_cross_validation_loss.csv',loss, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd45739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
