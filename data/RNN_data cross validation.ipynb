{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80dc7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4a8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655dbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = open(\"data_shuffle_input.csv\")\n",
    "inputs = np.genfromtxt(a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b65120",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open(\"data_shuffle_target.csv\")\n",
    "targets = np.genfromtxt(c, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a719ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "inputs = inputs.reshape(inputs.shape[0],1,784)\n",
    "inputs = inputs/255\n",
    "print(len(inputs[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48f0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effbaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c1ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for i in range(len(targets)):\n",
    "    if targets[i][0] == 1:\n",
    "        num.append(0)\n",
    "    if targets[i][1] == 1:\n",
    "        num.append(1)\n",
    "    if targets[i][2] == 1:\n",
    "        num.append(2)\n",
    "    if targets[i][3] == 1:\n",
    "        num.append(3)\n",
    "    if targets[i][4] == 1:\n",
    "        num.append(4)\n",
    "    if targets[i][5] == 1:\n",
    "        num.append(5)\n",
    "    if targets[i][6] == 1:\n",
    "        num.append(6)\n",
    "    if targets[i][7] == 1:\n",
    "        num.append(7)\n",
    "    if targets[i][8] == 1:\n",
    "        num.append(8)\n",
    "    if targets[i][9] == 1:\n",
    "        num.append(9)\n",
    "num = np.asarray(num)        \n",
    "print(type(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc6b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 2.0998 - acc: 0.3212\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 1.4909 - acc: 0.7475\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.9625 - acc: 0.8338\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 209us/sample - loss: 0.6492 - acc: 0.8575\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 211us/sample - loss: 0.4832 - acc: 0.8775\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 275us/sample - loss: 0.3866 - acc: 0.8950\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 284us/sample - loss: 0.3187 - acc: 0.9137\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 305us/sample - loss: 0.2732 - acc: 0.9337\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 0.2320 - acc: 0.9513\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 0.1982 - acc: 0.9638\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.1725 - acc: 0.9688\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 0.1517 - acc: 0.9725\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.1321 - acc: 0.9800\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 0.1150 - acc: 0.9875\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.1021 - acc: 0.9862\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 0.0897 - acc: 0.9900\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0790 - acc: 0.9937\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.0701 - acc: 0.9937\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.0618 - acc: 0.9950\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.0556 - acc: 0.9950\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.0495 - acc: 0.9975\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 0.0452 - acc: 0.9987\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.0408 - acc: 0.9987\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.0076 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 9 2 6 9 5 4 8 7 1 5 2 6 7 1 5 6 8 1 1 5 9 4 9 4 6 6 9 8 7 0 3 7 3 4 7\n",
      " 6 4 5 4 9 4 4 9 0 3 2 4 8 5 6 7 7 6 1 1 2 4 0 9 2 8 5 9 7 3 8 4 2 3 2 5 8\n",
      " 4 5 4 8 8 5 9 0 4 2 9 8 0 2 5 3 6 1 2 6 5 9 1 6 0 6 4 1 8 4 6 9 7 0 6 4 7\n",
      " 7 1 5 4 9 9 9 0 2 7 5 2 3 6 3 7 2 0 0 6 7 4 4 6 0 0 6 3 7 1 9 2 1 3 0 9 0\n",
      " 7 4 6 5 9 0 9 3 0 1 7 8 8 7 4 4 1 1 3 1 2 9 6 4 5 2 1 7 8 2 5 4 1 1 6 5 8\n",
      " 5 1 1 2 0 7 4 2 6 0 2 3 9 3 3]\n",
      "accuracy is 0.895\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 527us/sample - loss: 2.0723 - acc: 0.4950\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.4445 - acc: 0.8062\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.9053 - acc: 0.8375\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.5966 - acc: 0.8575\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.4389 - acc: 0.8863\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.3435 - acc: 0.9087\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.2817 - acc: 0.9250\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.2355 - acc: 0.9413\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.2013 - acc: 0.9563\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.1675 - acc: 0.9675\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1489 - acc: 0.9712\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1292 - acc: 0.9812\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.1132 - acc: 0.9837\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.0967 - acc: 0.9900\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0874 - acc: 0.9925\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0760 - acc: 0.9950\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0672 - acc: 0.9962\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.0591 - acc: 0.9975\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.0541 - acc: 0.9987\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.0476 - acc: 0.9987\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.0074 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 1 8 2 9 3 3 3 9 9 1 4 3 6 5 3 7 7 0 0 4 5 5 3 3 1 0 5 3 2 8 0 8 6 4 9\n",
      " 4 6 6 4 5 9 9 0 9 1 7 7 5 4 8 7 3 0 1 9 1 6 4 0 9 3 6 0 6 6 1 6 5 3 1 9 2\n",
      " 2 2 5 3 8 7 7 5 2 2 5 3 2 4 3 7 8 8 7 4 7 9 0 1 3 4 5 0 4 6 7 3 0 7 9 8 1\n",
      " 9 5 3 5 5 3 3 4 8 0 9 2 0 4 7 6 8 9 0 4 6 3 9 6 2 1 3 4 8 3 6 2 1 7 0 9 5\n",
      " 6 2 3 3 5 3 2 3 4 0 9 2 7 9 5 7 9 4 6 9 1 7 0 3 4 7 5 3 4 9 7 4 5 6 1 5 3\n",
      " 4 5 5 7 3 1 2 6 2 6 2 0 9 3 8]\n",
      "accuracy is 0.86\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 410us/sample - loss: 2.1008 - acc: 0.4275\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.4930 - acc: 0.7312\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.9736 - acc: 0.8062\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.6658 - acc: 0.8475\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.4957 - acc: 0.8725\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.3926 - acc: 0.9038\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.3242 - acc: 0.9237\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.2693 - acc: 0.9350\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.2322 - acc: 0.9463\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.1987 - acc: 0.9675\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.1751 - acc: 0.9725\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.1517 - acc: 0.9775\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.1326 - acc: 0.9812\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.1188 - acc: 0.9850\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.1058 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.0922 - acc: 0.9925\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.0834 - acc: 0.9925\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.0730 - acc: 0.9937\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.0652 - acc: 0.9962\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.0589 - acc: 0.9962\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0530 - acc: 0.9987\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.0478 - acc: 0.9987\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.0260 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0083 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 1 4 5 7 9 6 2 5 6 2 7 4 3 0 5 0 4 9 7 7 3 7 5 6 4 1 2 5 9 5 0 2 3 7 8\n",
      " 4 2 2 0 0 4 8 8 8 5 9 5 2 9 9 5 4 5 9 0 7 1 0 4 6 7 8 8 2 7 7 7 3 7 6 3 4\n",
      " 1 9 7 0 0 2 2 2 2 0 3 9 1 5 5 0 0 2 6 2 2 0 6 5 4 8 8 3 8 0 3 5 8 4 3 1 6\n",
      " 9 7 7 5 1 4 8 7 8 0 2 7 9 5 1 8 8 1 4 2 6 1 9 9 8 1 7 9 4 5 5 4 4 9 6 2 0\n",
      " 1 8 2 1 1 7 8 6 6 0 9 7 6 8 1 3 5 7 4 0 8 6 0 6 3 7 9 8 7 9 4 6 6 2 6 1 9\n",
      " 2 3 3 7 5 1 9 5 4 2 8 2 6 3 8]\n",
      "accuracy is 0.875\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 445us/sample - loss: 2.0826 - acc: 0.4263\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.4635 - acc: 0.7675\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.9366 - acc: 0.8175\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.6475 - acc: 0.8450\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.4980 - acc: 0.8725\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4018 - acc: 0.8900\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3385 - acc: 0.9087\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.2887 - acc: 0.9325\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.2472 - acc: 0.9450\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.2149 - acc: 0.9538\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.1894 - acc: 0.9588\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.1670 - acc: 0.9700\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.1440 - acc: 0.9775\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.1259 - acc: 0.9825\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.1114 - acc: 0.9900\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.0999 - acc: 0.9900\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.0883 - acc: 0.9912\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0775 - acc: 0.9937\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.0685 - acc: 0.9937\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.0599 - acc: 0.9975\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.0541 - acc: 0.9975\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0486 - acc: 0.9987\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0440 - acc: 0.9987\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0083 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 3 7 2 6 0 2 8 5 1 7 8 6 3 1 3 1 3 5 5 0 8 7 5 9 9 2 5 6 5 7 6 3 8 6\n",
      " 7 2 0 0 1 7 2 5 3 7 1 1 1 3 9 9 5 2 6 6 8 4 5 3 7 0 0 1 7 9 1 3 6 4 6 6 3\n",
      " 5 4 2 9 2 9 6 3 2 7 6 0 1 2 5 0 0 7 6 2 8 5 3 8 8 8 4 4 4 6 0 8 8 9 9 3 4\n",
      " 8 7 9 0 4 1 1 4 8 8 3 4 4 3 6 7 7 3 6 3 9 1 1 7 6 7 0 0 3 8 3 0 5 1 1 2 1\n",
      " 8 3 6 7 2 1 7 5 0 7 9 7 1 0 8 2 3 6 3 6 4 2 6 6 1 9 3 6 9 4 7 4 2 4 0 8 5\n",
      " 8 9 8 1 1 1 9 6 4 0 6 8 8 7 8]\n",
      "accuracy is 0.895\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 800 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 600us/sample - loss: 2.1255 - acc: 0.4062\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5256 - acc: 0.7500\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.9821 - acc: 0.8238\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.6525 - acc: 0.8625\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.4824 - acc: 0.8838\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.3852 - acc: 0.8900\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.3163 - acc: 0.9150\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.2722 - acc: 0.9337\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.2356 - acc: 0.9413\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.2016 - acc: 0.9513\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.1778 - acc: 0.9663\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.1547 - acc: 0.9737\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.1356 - acc: 0.9800\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.1189 - acc: 0.9862\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.1067 - acc: 0.9862\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0936 - acc: 0.9887\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0819 - acc: 0.9912\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.0729 - acc: 0.9925\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.0655 - acc: 0.9962\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.0588 - acc: 0.9987\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.0516 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0477 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.0081 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 1 8 0 6 9 9 2 0 3 6 7 1 3 3 5 8 0 5 7 2 3 9 0 5 7 2 5 2 3 8 5 8 0 8\n",
      " 9 8 7 9 8 7 5 0 5 1 7 3 1 6 3 6 5 6 9 2 5 1 3 6 2 9 1 4 8 7 8 0 5 2 7 4 0\n",
      " 2 9 0 2 2 7 5 8 8 2 2 9 6 9 4 2 0 0 5 7 3 9 1 8 5 1 1 9 0 4 2 0 1 4 0 1 2\n",
      " 2 8 0 0 1 6 5 4 4 4 8 1 5 8 8 1 4 8 8 3 9 0 7 4 8 4 2 2 5 8 1 3 9 1 0 3 0\n",
      " 8 3 4 9 2 4 0 6 8 0 2 9 9 5 7 1 7 2 3 5 7 5 1 8 5 0 1 2 1 5 1 4 8 4 0 2 9\n",
      " 0 0 1 6 0 6 8 5 8 3 4 8 6 3 5]\n",
      "accuracy is 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5)\n",
    "acc_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets, num):\n",
    "\n",
    "  # Define the model architecture\n",
    "    rnn_model = Sequential()\n",
    "    #rnn_model.add(Flatten())\n",
    "    rnn_model.add(LSTM(256,input_shape=inputs[0].shape,activation=\"tanh\"))\n",
    "    #rnn_model.add(SimpleRNN(128,input_shape=xtrain[0].shape,return_sequences=True))\n",
    "    #rnn_model.add(SimpleRNN(128))\n",
    "    rnn_model.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "  # Compile the model\n",
    "    rnn_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = rnn_model.fit(inputs[train], targets[train],\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "    scores = rnn_model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    #print(f'Score for fold {fold_no}: {rnn_model.metrics_names[0]} of {scores[0]}; {rnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    #acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    predictions = rnn_model.predict(inputs[test])\n",
    "    classes = np.argmax(predictions, axis = 1)\n",
    "    print(num[test])\n",
    "    acc_per_fold.append(accuracy_score(num[test],classes))\n",
    "    \n",
    "    print('accuracy is ' + str(accuracy_score(num[test],classes)))\n",
    "    \n",
    "  # Generate generalization metrics\n",
    "    \n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e9b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Accuracy: 0.86%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Accuracy: 0.875%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Accuracy: 0.88%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.881 (+- 0.01319090595827293)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d129740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.4574938855320215 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.6481446093320846 - Accuracy: 0.86%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.4315407514572144 - Accuracy: 0.875%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.3721163368225098 - Accuracy: 0.895%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5561678981781006 - Accuracy: 0.88%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.881 (+- 0.01319090595827293)\n",
      "> Loss: 0.4930926962643861\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106a0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
